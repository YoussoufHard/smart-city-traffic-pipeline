# Guide Technique Profond : Smart City Traffic Pipeline

Ce document est con√ßu pour vous donner une ma√Ætrise totale du projet. Si vous lisez et comprenez ce qui suit, vous pourrez expliquer l'architecture compl√®te, chaque choix technologique et le flux de donn√©es sans aucune lacune.

---

## 1. Vision d'Ensemble : L‚ÄôArchitecture Lambda (Simplifi√©e)
Le projet suit un mod√®le classique du Big Data. On ne se contente pas de stocker des donn√©es, on cr√©e un **syst√®me √† couches** :

1.  **Couche d'Ingestion (Temps R√©el)** : Capturer les donn√©es sans en perdre une seule.
2.  **Couche de Stockage (Data Lake)** : Garder la v√©rit√© brute (Raw Data) pour l'histoire.
3.  **Couche de Traitement (Batch)** : Transformer la bouillie de donn√©es en indicateurs intelligents.
4.  **Couche de Service (Serving Layer)** : Rendre les r√©sultats rapides √† lire pour l'utilisateur.

---

## 2. Le R√¥le de Chaque Composant (Le "Pourquoi")

### üõ∞Ô∏è Python Generator (Les Capteurs IoT)
*   **R√¥le** : Simule les milliers de cam√©ras et capteurs dans la ville.
*   **Pourquoi Python ?** Tr√®s simple pour faire du JSON et parler √† Kafka.
*   **Concept Cl√©** : Il g√©n√®re des donn√©es **non-structur√©es/semi-structur√©es** (JSON).

### üì• Apache Kafka (Le Buffer Intelligent)
*   **Pourquoi ne pas envoyer direct dans HDFS ?** 
    - Parce que HDFS n'est pas fait pour recevoir 1000 petits messages par seconde. Il s'√©puiserait.
    - Kafka agit comme un **amortisseur**. Il encaisse les pics de trafic. Si HDFS tombe en panne pendant 10 min, Kafka garde les messages en m√©moire (Retention).
*   **Terminologie** : Le g√©n√©rateur est un **Producer**, Kafka est le **Broker**.

### üêò HDFS (Le Data Lake - Raw Zone)
*   **R√¥le** : Stocker des volumes massifs (Terraoctets) √† bas co√ªt.
*   **Pourquoi ici ?** On y stocke les donn√©es **brutes**. Si on se trompe dans nos calculs Spark demain, on pourra toujours repartir des donn√©es brutes stock√©es ici.
*   **Partitionnement** : On range par `date=YYYY-MM-DD`. C'est vital. Sans √ßa, pour analyser le trafic d'hier, Spark devrait scanner TOUT le disque depuis le d√©but du projet.

### ‚ö° Apache Spark (Le Muscle du Calcul)
*   **R√¥le** : C'est le moteur de traitement distribu√©.
*   **Pourquoi Spark ?** Il est 100x plus rapide qu'Hadoop MapReduce car il travaille en **RAM**.
*   **Transformation** : Il prend le JSON illisible, calcule des moyennes (vitesse moyenne, nombre de voitures) et cr√©e des colonnes propres.

### üêò HDFS (Analytics Zone - Parquet)
*   **Pourquoi Parquet ?** 
    - Le JSON est un format "ligne". Le Parquet est un format **"colonnaire"**.
    - Si vous voulez juste la "vitesse moyenne", Spark ne lira que la colonne "vitesse" sur le disque. C'est un gain de performance √©norme pour le Big Data.

### üêò PostgreSQL (La Serving Layer - LA R√âPONSE √Ä VOTRE QUESTION)
*   **VOTRE QUESTION** : *"Pourquoi Postgres alors qu'on a HDFS ?"*
*   **LA R√âPONSE** : **La Latence**.
    - **HDFS/Spark** sont des outils "Batch". Si vous posez une question √† HDFS, il met 10 √† 30 secondes √† r√©pondre car il doit scanner des fichiers.
    - **PostgreSQL** est une base de donn√©es relationnelle index√©e. Elle r√©pond en **quelques millisecondes**.
    - **Grafana** a besoin de fluidit√©. Quand vous changez de filtre sur un dashboard, vous ne voulez pas attendre 30 secondes. On copie donc les *r√©sultats agr√©g√©s* de Spark dans Postgres pour que Grafana soit ultra-r√©actif.
*   **HDFS** = Archives g√©antes (Big Data).
*   **Postgres** = Tableaux de bord rapides (Fast Data).

### üõ†Ô∏è Apache Airflow (Le Chef d'Orchestre)
*   **R√¥le** : Il ne traite pas de donn√©es. Il dit aux autres QUAND travailler.
*   - "Il est 8h00, Spark, lance le calcul d'hier."
    - "Si Spark √©choue, renvoie-moi une alerte."
    - "V√©rifie que les donn√©es sont bien arriv√©es dans HDFS avant de commencer."

---

## 3. Le Voyage d'une Donn√©e (Flux Complet)

1.  **G√©n√©ration** : Une voiture passe devant le capteur `S1` -> JSON cr√©√©.
2.  **Transit** : Le message arrive dans le topic Kafka `traffic-events`.
3.  **Archivage** : Le consumer lit Kafka et √©crit le JSON dans `/data/raw/traffic/date=2024...` sur HDFS.
4.  **R√©veil** : Airflow sonne l'alarme -> Lance le Job Spark.
5.  **Intelligence** : Spark lit les 10 000 JSON dans HDFS, calcule que la vitesse moyenne est de 42 km/h.
6.  **Publication** : Spark √©crit "42 km/h" dans **Postgres**.
7.  **Visualisation** : Grafana interroge Postgres et dessine le point "42" sur le graphique.

---

## 4. Concepts Techniques Avanc√©s (Pour briller en soutenance)

*   **Idempotence** : Le pipeline est con√ßu pour pouvoir √™tre relanc√© (en mode "Overwrite" ou "Append") sans corrompre les r√©sultats.
*   **Scalabilit√©** : Si la ville passe de 10 √† 10 000 capteurs, il suffit d'ajouter des "Workers" √† Spark et des partitions √† Kafka. L'architecture ne change pas.
*   **Consistance** : L'utilisation de Parquet garantit que les sch√©mas de donn√©es (noms des colonnes, types) sont respect√©s et optimis√©s.
